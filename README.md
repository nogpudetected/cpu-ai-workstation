# CPU-Optimized Local AI Stack

### Ollama + OpenWebUI with Custom CPU Backends for Stable Diffusion & TTS

This repository provides a fully local **CPU-only AI environment** combining:

* **Ollama** for LLM inference
* **OpenWebUI** as the unified frontend
* **Custom Python backends** for:

  * Stable Diffusion (CPU-only image generation)
  * Chatterbox TTS (offline speech synthesis)

The stack is designed for systems without GPUs: homelabs, mini-PCs, servers, and privacy-focused offline setups.

---

## âœ¨ Features

* **LLMs via Ollama** â€” fully local and CPU-optimized
* **Stable Diffusion CPU backend** â€” optimized inference pipeline
* **Chatterbox TTS backend** â€” lightweight text-to-speech
* **OpenWebUI integration** â€” UI support for LLM, SD, and TTS
* **Modular architecture** â€” each backend runs independently
* **Zero GPU required**

---

## ğŸ“ Repository Structure

```
repo/
â”œâ”€â”€ backends/
â”‚   â”œâ”€â”€ sd_cpu_backend/
â”‚   â”‚   â”œâ”€â”€ sd_backend.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ tts_chatterbox_backend/
â”‚       â”œâ”€â”€ chatterbox_backend.py
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ README.md
â”œâ”€â”€ openwebui/
â”‚   â”œâ”€â”€ config_example.json
â”‚   â””â”€â”€ backends_registration.md
â”œâ”€â”€ ollama/
â”‚   â””â”€â”€ models.md
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ image_generation_example.py
â”‚   â”œâ”€â”€ tts_example.py
â”‚   â””â”€â”€ prompts.md
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```

---

## ğŸ›  Installation

### 1. Clone the repository

```bash
git clone https://github.com/<your-username>/<your-repo>.git
cd <your-repo>
```

### 2. Install backend dependencies

**Stable Diffusion (CPU)**

```bash
cd backends/sd_cpu_backend
pip install -r requirements.txt
```

**Chatterbox TTS**

```bash
cd ../tts_chatterbox_backend
pip install -r requirements.txt
```

### 3. Start the backends

**Start SD backend**

```bash
python sd_backend.py
```

**Start TTS backend**

```bash
python chatterbox_backend.py
```

### 4. Configure OpenWebUI

```bash
cp openwebui/config_example.json ~/.config/openwebui/config.json
```

### 5. (Optional) Install Ollama models

```bash
ollama pull llama3
ollama pull qwen2
```

---

## ğŸ§ª Usage Examples

### Image Generation

```python
from sd_backend import generate_image

img = generate_image(
    prompt="Watercolor painting of a futuristic city",
    steps=20
)
img.save("result.png")
```

### Text-to-Speech

```python
from chatterbox_backend import synthesize

audio = synthesize("Hello! This audio was generated on CPU.")
with open("speech.wav", "wb") as f:
    f.write(audio)
```

---

## âš™ï¸ Configuration

### Environment Variables

```
SD_MODEL_PATH=./models/sd/
TTS_MODEL_PATH=./models/chatterbox/
BACKEND_PORT_SD=5001
BACKEND_PORT_TTS=5002
```

### OpenWebUI backend registration

```json
"custom_backends": [
    { "name": "sd_cpu", "url": "http://localhost:5001" },
    { "name": "chatterbox_tts", "url": "http://localhost:5002" }
]
```

---

## ğŸ§± Architecture

```
OpenWebUI
   â”‚
   â”œâ”€â”€ Ollama (LLMs)
   â”œâ”€â”€ SD CPU Backend (Stable Diffusion)
   â””â”€â”€ Chatterbox TTS Backend
```

All components run fully locally and **it is not needed any GPU**.

---

## ğŸ§­ Roadmap

* [ ] CPU-only Docker support
* [ ] Unified installation script
* [ ] Quantized SD pipeline
* [ ] Whisper CPU backend
* [ ] Benchmark suite

---

## ğŸ¤ Contributing

Pull requests, issues, and suggestions are welcome.

---

## ğŸ“ License

Released under the **MIT License**. See `LICENSE` for details.
